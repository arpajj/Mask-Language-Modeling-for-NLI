{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Helpers import main, LoadDatasets\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer and model for masked language modeling\n",
    "tokenizer_bert = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model_bert = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RoBERTa tokenizer and model\n",
    "tokenizer_roberta = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model_roberta = RobertaForMaskedLM.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataloader = LoadDatasets.my_dataloader\n",
    "all_labels = LoadDatasets.all_labels\n",
    "probabilities_over_dateset = main.prob_distribution_over_vocab_with_batch(model_gpt2, tokenizer_gpt2, my_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.5655\n"
     ]
    }
   ],
   "source": [
    "#results_bert_flattened = [inner_list for outer_list in probabilities_over_dateset for inner_list in outer_list]\n",
    "results_gpt2_flattened = [inner_list for outer_list in probabilities_over_dateset for inner_list in outer_list]\n",
    "#results_roberta_flattened = [inner_list for outer_list in results_roberta for inner_list in outer_list]\n",
    "\n",
    "predicted_labels = []\n",
    "for item in results_gpt2_flattened:\n",
    "    if item[0] > item[1] or item[0] > item[2]: # (true > false) and (true > unknown)\n",
    "        predicted_labels.append(1) # append 0 for entailment \n",
    "    elif item[2] > item[0] and item[2] > item[1]: # (unknown > true) and (unknown > false)\n",
    "        predicted_labels.append(1) # append 1 for neutral \n",
    "    else: \n",
    "        predicted_labels.append(2) # else append 2 for contradiction\n",
    "    \n",
    "print(\"The accuracy score is: {:.4f}\".format(accuracy_score(all_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 50257])\n",
      "[7942, 9562, 34680]\n",
      "tensor([[3.5668e-05, 1.1464e-04, 1.9851e-06],\n",
      "        [5.8537e-05, 1.3625e-04, 3.9739e-06],\n",
      "        [5.9062e-05, 7.9166e-05, 2.5659e-06],\n",
      "        [5.0147e-06, 1.1541e-05, 8.1211e-06],\n",
      "        [4.0610e-06, 9.5627e-06, 1.1525e-05],\n",
      "        [2.7224e-05, 9.9845e-05, 1.4174e-06],\n",
      "        [7.0673e-05, 2.9570e-04, 3.2609e-06],\n",
      "        [1.0684e-04, 3.0614e-04, 4.8399e-06]])\n",
      "[[[3.566766463336535e-05, 0.0001146413924288936, 1.9850749595207162e-06], [5.853661059518345e-05, 0.00013624713756144047, 3.973904767917702e-06], [5.9062065702164546e-05, 7.916623872006312e-05, 2.5659082893980667e-06], [5.0147205001849215e-06, 1.1540716513991356e-05, 8.12108555692248e-06], [4.061021627421724e-06, 9.562720151734538e-06, 1.1524550245667342e-05], [2.722367935348302e-05, 9.984481584979221e-05, 1.4174349871609593e-06], [7.067287515383214e-05, 0.00029569503385573626, 3.2609041227260605e-06], [0.00010684038716135547, 0.0003061415336560458, 4.83985149912769e-06]]]\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "tokens_of_interest = [\"true\", \"false\", \"unknown\"]\n",
    "probs_over_batched_dataset = []\n",
    "for batch in my_dataloader:\n",
    "    sentences = [sentence.replace(\"[MASK]\", '_') for sentence in batch['sentence']]\n",
    "    tokenized_batch = tokenizer_gpt2(sentences)\n",
    "    tokenized_batch = main.transform_pad_batch(tokenized_batch, model_gpt2)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_gpt2(**tokenized_batch)\n",
    "    mask_token_indicies = []\n",
    "    \n",
    "    for item in tokenized_batch[\"input_ids\"]:\n",
    "        mask_token_indicies.append(torch.where(item!=0)[0][-1].item())\n",
    "    \n",
    "    extracted_rows = outputs.logits[torch.arange(outputs.logits.size(0)), mask_token_indicies]\n",
    "    probabilities = torch.functional.F.softmax(extracted_rows, dim=-1)\n",
    "    print(probabilities.shape)\n",
    "    inter_tokens_ids = main.get_interest_tokens(tokenizer_gpt2.get_vocab(), tokens_of_interest)\n",
    "    print(inter_tokens_ids)\n",
    "    probabilites_of_interest = probabilities[:, inter_tokens_ids]\n",
    "    print(probabilites_of_interest)\n",
    "    probs_over_batched_dataset.append(probabilites_of_interest.tolist())\n",
    "    print(probs_over_batched_dataset)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
